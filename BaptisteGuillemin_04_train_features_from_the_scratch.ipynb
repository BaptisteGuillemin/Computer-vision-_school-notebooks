{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Featurs Extraction for image classification ==> toward learning\n",
        "\n",
        "We will learn in this exercise how to:\n",
        "\n",
        "1.   Prepare image to be classified\n",
        "2.   Create an image classifier\n",
        "3.   Classify an image using a classifier created from the scratch\n",
        "\n",
        "\n",
        "\n",
        "Let's recognize the orinatation of bar (white color) in the following images (horizontal and vertical) (background is black)\n",
        "\n",
        "\n",
        "![picture](https://drive.google.com/uc?id=1rLaKnxTAlIzOjH6rWpYIsJIFc_v-WZbZ)  ![picture](https://drive.google.com/uc?id=1RW32gK9PvqDLO7vTp62qQsS0LKF2NvTk)\n",
        "\n",
        "\n",
        "Let’s consider these simple images to have a size of 3×3 (3 pixels of width and 3 of height).\n",
        "Let’s now focus only on one image, we will take the vertical one. The image to the computer will look like this:\n",
        "\n",
        "Vertical:\n",
        "[[ 0 255 0]\n",
        "[ 0 255 0]\n",
        "[ 0 255 0]]\n",
        "\n",
        "\n",
        "Download images: [vertical](https://drive.google.com/file/d/1AF6j9fU3j5GtQPCuZ5OyqOT_paF-eItn/view?usp=share_link)\n",
        "[Horizontal](https://drive.google.com/file/d/1EjHgADGmJT0rJa8q8TFAB4_OT2ORiicm/view?usp=share_link) \n"
      ],
      "metadata": {
        "id": "qcohXr0AwM8N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gdown\n",
        "!gdown https://drive.google.com/uc?id=1AF6j9fU3j5GtQPCuZ5OyqOT_paF-eItn\n",
        "!gdown https://drive.google.com/uc?id=1EjHgADGmJT0rJa8q8TFAB4_OT2ORiicm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GGFpEXtcAzVf",
        "outputId": "2f9661d0-c6dd-4d4a-f3dd-e354af6495fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.9/dist-packages (4.6.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from gdown) (4.65.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.9/dist-packages (from gdown) (4.11.2)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.9/dist-packages (from gdown) (2.27.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from gdown) (1.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from gdown) (3.10.7)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.9/dist-packages (from beautifulsoup4->gdown) (2.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->gdown) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->gdown) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->gdown) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->gdown) (2022.12.7)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1AF6j9fU3j5GtQPCuZ5OyqOT_paF-eItn\n",
            "To: /content/vertical.png\n",
            "100% 557/557 [00:00<00:00, 729kB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1EjHgADGmJT0rJa8q8TFAB4_OT2ORiicm\n",
            "To: /content/horizontal.png\n",
            "100% 552/552 [00:00<00:00, 839kB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "QWOKVXcV02-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Applying convolution\n",
        "\n",
        "We add a filter to convolute the image and to extract feature. Fo simplicity, a filter in this case will be an array of the same size of the image so containing 9 numbers.\n",
        "\n",
        "\n",
        "```\n",
        "filter = [1, -1, 1, -1, 1, -1, 1, -1, 1]\n",
        "```\n",
        "\n",
        "Convolution (simple):\n",
        "\n",
        "\n",
        "```\n",
        "convolution = sum(img_flattened * filter)\n",
        "\n",
        "```\n",
        "Perform the steps:\n",
        "\n",
        "\n",
        "1.   Read \"horisontal.png\"\n",
        "\n",
        "2.   Normalize it\n",
        "3. Flatten the image\n",
        "4. Define the filter matrix\n",
        "5. Convlute the image using the filter\n",
        "6. Print the result of convolution\n",
        "7. read a new image \"vertical.png\" and repeat the steps from 2 to 6\n",
        "8. determine a condition that distinguish betwen vertical and horizontal features\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NoLxmlyY4SEH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img = cv2.imread('/content/horizontal.png', cv2.IMREAD_GRAYSCALE)\n",
        "print(img)\n",
        "\n",
        "# 1) Simplify image by dividing 255\n",
        "img = img / 255\n",
        "\n",
        "# 2) Flatten the image\n",
        "img_flattened = img.flatten()\n",
        "\n",
        "# 3) Filter\n",
        "filter = [1, -1, 1, \n",
        "          1, -1, 1, \n",
        "          1, -1, 1]\n",
        "\n",
        "# 4) Multiply filter * flattened image\n",
        "convolution = img_flattened * filter\n",
        "\n",
        "# 5) Sum\n",
        "sum_convolution = sum(convolution)\n",
        "print(sum_convolution)\n",
        "# 6) Condition\n",
        "if sum_convolution == 1:\n",
        "    print(\"Horizontal\")\n",
        "else:\n",
        "    print(\"Vertical\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3xm1A7qH2tF0",
        "outputId": "40eac491-31ec-47a7-fd77-2206aaa51d76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  0   0   0]\n",
            " [255 255 255]\n",
            " [  0   0   0]]\n",
            "1.0\n",
            "Horizontal\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Put the process in a function for tests\n",
        "Define a function to do the process (input: image, output vertical or horizontal)\n"
      ],
      "metadata": {
        "id": "dw7f6zgH6bmt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Put the process in a function\n",
        "\n",
        "def classify_image(img):\n",
        "    # 1) Simplify image by dividing 255\n",
        "    img = img / 255\n",
        "\n",
        "    # 2) Flatten the image\n",
        "    img_flattened = img.flatten()\n",
        "\n",
        "    # 3) Filter\n",
        "    filter = [1, -1, 1, 1, -1, 1, 1, -1, 1]\n",
        "\n",
        "    # 4) Multiply filter * flattened image\n",
        "    convolution = img_flattened * filter\n",
        "\n",
        "    # 5) Sum\n",
        "    sum_convolution = sum(convolution)\n",
        "\n",
        "    # 6) Condition\n",
        "    if sum_convolution == 1:\n",
        "        return \"Horizontal\"\n",
        "    else:\n",
        "        return \"Vertical\""
      ],
      "metadata": {
        "id": "QE7Ko-iQ6OGR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing your classifier \n",
        "We are going to test classifier with some new images of similar features.\n",
        "\n",
        "The idea would be that in only one line we can call the classifier and it is going to tell us whether the image is a vertical or a horizontal line.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "![picture](https://drive.google.com/uc?id=14_EzE6JI5ZIGNZT8X3uEBSkaSmcLqUr3) \n",
        "_________________\n",
        " ![picture](https://drive.google.com/uc?id=1J8ij0MPJZ1KekISjOPl1kWg-uMPMLp3J)\n",
        "____________________________________________________________________\n",
        "\n",
        "\n",
        "Download new images:  [bottom_Horizontal](https://drive.google.com/file/d/1hcacenV2IkOjANBZ3mLdklGYT_L6mwTB/view?usp=share_link), [left_vertical](https://drive.google.com/file/d/1D2tfKgTHGjLqvly0F6Qhm6B775gzNjX8/view?usp=share_link) , \n"
      ],
      "metadata": {
        "id": "1-sJXH5Z6lcV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img = cv2.imread(\"vertical.png\", cv2.IMREAD_GRAYSCALE)\n",
        "img2 = cv2.imread(\"horizontal.png\", cv2.IMREAD_GRAYSCALE)\n",
        "img3 = read \"bottom_horizontal.png\"\n",
        "img4 = read(\"left_vertical.png\"\n",
        "\n",
        "\n",
        "\n",
        "result = classify_image(img3)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6z3EX89-7XA",
        "outputId": "1114acbd-81ad-4d17-b131-e68f083c6890"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Horizontal\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is done by a pre-defined filter, that is able to detect the horizontal and vertical lines. \n",
        "\n",
        "The **drawback** of that classifier was that we needed to create manually the filter to classify the images. So if we wanted to classify different type of images, we would need again to create manually a new filter.\n",
        "\n"
      ],
      "metadata": {
        "id": "lurkdpTmACZW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classifier of Various Images \n",
        "To tackle the drawback of previous classifier, we have to let the computer do the task of defining the filter automatically, so that it will find a filter for different images of horizontal and vertical lines, bot not necessarily identical "
      ],
      "metadata": {
        "id": "sddWzJmwAuNv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Process the image within a function \n",
        "First of all, we create a function to preprocess the image before applying the classifier, so that instead of dividing each single image by 255 and flattening it, we will get in return this operation aleady executed by the function.\n",
        "\n",
        "The function preprocess_img will take the image path and give in return the image ready to bre processed by the classifier."
      ],
      "metadata": {
        "id": "hU4pomJ3BkTX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_img(path_img):\n",
        "  # read the image\n",
        "    \n",
        "\n",
        "    # Normalize the image\n",
        "    \n",
        "\n",
        "    # Flatten the image\n",
        "    \n",
        "    return flattened_image"
      ],
      "metadata": {
        "id": "bAsj8lb2Bvpx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flattened_vertical = preprocess_img(\"vertical.png\")\n",
        "flattened_horizontal = preprocess_img(\"horizontal.png\")"
      ],
      "metadata": {
        "id": "kKMriVs1By1m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Identify the filter \n",
        "To find the proper filter, it must give a unique indicator for each image of similar features ( different value for different image)\n",
        "If it would return the same result, would be a bad filter because no matter if you give a vertical line or a horizontal line you get the same result and there is no distinction.\n",
        "\n",
        "### How do we create the filter?\n",
        "We create the filter putting random numbers from -1 to 1. There is a numpy function that does that: np.random.randint().\n",
        "The size must be the same size of the images we want to multiply the filter with, so in this case is 9 numbers.\n",
        "\n",
        "`filter_images = np.random.randint(-1, 2, size=9)`\n",
        "\n",
        "Convolution operation (multiply the image with the filter and sum the result) for both images is to implemented\n",
        "\n",
        "Then, the result of the convolution for both images will be compared. If the result of the two images is different, we can say it’s a good filter and we can use that one. Otherwise it’s a bad filter and we want to discard it and continue to find the proper one.\n",
        "\n",
        "We will put everything into a loop, and keep looping until we find a good filter.\n",
        "\n"
      ],
      "metadata": {
        "id": "uN1zEzYyB8Ma"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Exercise:\n",
        "Consider both input flatten vertical and horizontal, within a loop, generate a filter randomly, and convolute the image and check if the results of two convolutions are different or not.\n",
        "Once you find the filter that make the convolutions different, consider it as the good and exit. It is interesting to print the number of attempts "
      ],
      "metadata": {
        "id": "s04DFDVNUZo5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "while True:\n",
        "    # here your code \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4CK7KtjOFQrc",
        "outputId": "8119d629-c331-4aaa-c498-865e76cac6c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Good filter\n",
            "Filter:  [-1 -1  1 -1  0 -1  0  1  0]\n",
            "0.0\n",
            "-2.0\n",
            "Attempts:  1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Validate filter on more images\n",
        "\n",
        "If we were able to detect  easily and quickly a filter that would work having just one image per class, one image for the “Vertical” and one for the “Horizontal”, \n",
        "\n",
        "**So how would this method perform if we had more images per class?**\n",
        "\n",
        "\n",
        "We’re going to do that right now, but to make the detection more challenging, we will try this time with more difficult images of size 5×5, as shown in the following\n",
        "\n",
        "\n",
        "download them from [here:](https://drive.google.com/file/d/1zKv6wwlI_PGrgicK7DxFT6R9VvbdwW86/view?usp=share_link) "
      ],
      "metadata": {
        "id": "sKylk0EyfZQX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "**Squares:**\n",
        "\n",
        "![picture](https://drive.google.com/uc?id=1tPXMD28FwrsRby00npDK9F6BTdsRzc8r) \n",
        "_________________\n",
        "\n",
        "\n",
        " **Crosses:**\n",
        "\n",
        " ![picture](https://drive.google.com/uc?id=1wcgoMNNu4rwZ9YAiGqENRBF_SOXk4brb)\n",
        "____________________________________________________________________\n",
        "\n",
        "\n",
        "Now, the task gets more challenging.\n",
        "We don’t need to load just two images, but more images and the condition after the convolution must satisfy more images for the same class.\n",
        "\n",
        "Let’s start by taking the path of all the 10 images, so we can easily load them. For the squares I have 5 images and their name starts with square, so I take all the images with square on their name. Same operation I do for the crosses.\n",
        "\n",
        "```\n",
        "squares = glob.glob(\"square*.png\")\n",
        "crosses = glob.glob(\"cross*.png\")\n",
        "```\n",
        "\n",
        "We then need to run a while loop. We need the while loop to keep looking for a filter until we get a good one. This time we also add a switch button because it won’t be so easy to break the loop as we did on the previous code with just the break operator.\n",
        "\n",
        "Inside the loop we generate a random filter.\n",
        "\n",
        "Then we load the 5 squares and 5 crosses and we make the convolution for each single image.\n",
        "\n",
        "In order to consider the filter a good filter, we set two requirements:\n",
        "- all the squares need to be bigger or equal to 0, so if the result is different we break the for loop and we go back to the while loop and start everything until all the 5 squares satisfy the condition to be greater or equal to 0.\n",
        "\n",
        "- The same is for the crosses, if they’re not less than 0, we break the for loop.\n",
        "\n",
        "**How do we know when all the 5 squares and 5 crosses satisfy the requirements?**\n",
        "\n",
        "We know it if we’re able to get through all the images without breaking the loop. So we set the final condition, if count is 4 it means we were able to loop through all the 5 images, so the filter is good.\n",
        "At this point we set good_filter to True and the while loop will stop running.\n",
        "\n"
      ],
      "metadata": {
        "id": "CWVTfnnINmUf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "\n",
        "\n",
        "\n",
        "print(\"Filter:\", filter_images)\n",
        "print(\"Attempts:\", count)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NnE5UAx3g9dy",
        "outputId": "f4d1ba71-1ca4-4220-df9a-66b6afa39b26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['square_br.png', 'square_center.png', 'square_around.png', 'square_centerup.png', 'square_lu.png']\n",
            "['cross_ur.png', 'cross_cr.png', 'cross_centre.png', 'cross_ul.png', 'cross_bl.png']\n",
            "Filter: [ 0  1  1  1 -1  0  1 -1  0  0  0 -1  0  1 -1 -1 -1  1  0  0  0  1 -1 -1\n",
            "  1]\n",
            "Attempts: 732498\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test the found filter with a new image\n",
        "\n",
        "Once we find the filter, we can be sure that tha image classifier will work with the 5 images we used to find the filter, as it was tested exactly for that.\n",
        "\n",
        "Let’s adjust a bit the classifier using the filter you’ve just generated. You might have a different filter than the one I have, so you can use the one you got if you prefer.\n",
        "\n",
        "The filter this time is 25 numbers, as the images are of size 5×5 (which is a total of 25 pixels).\n",
        "\n",
        "But what if we try it with some image that we never used before?"
      ],
      "metadata": {
        "id": "U6RK7vSwz1gI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#filter = [ 1,  1, -1,  1,  0,  0, -1,  0,  1, -1,  0,  0, -1,  0, -1, -1, -1,  1,  0,  1,  1, -1, -1,  0, 1]\n",
        "\n",
        "filter =  [ 0,  1 , 1,  1, -1,  0,  1, -1,  0,  0,  0 ,-1,  0,  1, -1, -1, -1,  1,  0,  0,  0,  1, -1, -1,1]\n",
        "def classify_image(img, filter):\n",
        "    "
      ],
      "metadata": {
        "id": "ZqvEvwUTz0-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = cv2.imread(\"Square_test.png\", cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "\n",
        "result = classify_image(img,filter)\n",
        "print(result)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "huQVokXe1ADe",
        "outputId": "ce619f01-b0bd-40de-fdd0-d4c0bec85bd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Square\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.figure(figsize=(20, 9))\n",
        "plt.imshow(cv2.resize(img, (500, 500), interpolation=0), 'gray'),plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 559
        },
        "id": "3iBMLr4jFrab",
        "outputId": "58792f41-5185-42d6-c0a6-c73aa38d842b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x648 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<matplotlib.image.AxesImage at 0x7fe7c0276340>, None)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Credits: [Sergio Canu](https://pysource.com/)"
      ],
      "metadata": {
        "id": "nUJRgzjg2gBa"
      }
    }
  ]
}